# Основы работы с Greenplum

## Содержание
1. [Дистрибуция и создание таблиц](#дистрибуция-и-создание-таблиц)
   - [Обзор](#обзор)
   - [Цели](#цели)
   - [Структура базы данных](#структура-базы-данных)
   - [Ключевые особенности](#ключевые-особенности)
   - [Приобретенные навыки и компетенции](#приобретенные-навыки-и-компетенции)
2. [Интеграция с внешними системами](#интеграция-с-внешними-системами)
   - [Описание выполненной работы](#описание-выполненной-работы)
   - [Приобретенные навыки и компетенции](#приобретенные-навыки-и-компетенции-1)

## Дистрибуция и создание таблиц

### Обзор

"Дистрибуция и создание таблиц" — это проект, сосредоточенный на разработке оптимизированной базы данных для отслеживания продаж, каналов распределения и данных о продуктах. Проект моделирует реальный сценарий, в котором эффективное хранение, распределение и анализ больших объемов данных имеют критическое значение. База данных использует такие техники, как партиционирование, сжатие данных и распределение для повышения производительности и масштабируемости.

Этот проект идеален для изучения проектирования баз данных, хранения данных и аналитики в контексте данных о продажах.

### Цели

1. **Проектирование базы данных**: Изучение проектирования и реализации фактических и размерных таблиц с использованием стратегий партиционирования и распределения.
2. **Оптимизация производительности**: Изучение того, как партиционирование, сжатие данных и репликация могут улучшить скорость запросов и эффективность хранения для больших объемов данных.

### Структура базы данных

База данных следует структуре "звезда" с таблицами фактов и справочниками, организованными следующим образом:

#### Таблицы фактов:
- **sales** (`std7_170.sales`):
  - Эта таблица отслеживает транзакции по продажам.
  - **Столбцы**: `date`, `region`, `material`, `distr_chan`, `quantity`, `check_nm`, `check_pos`
  - **Партиционирование**: По `date` (на основе диапазона).
  - **Распределение**: По `check_nm`.
  - **Сжатие**: `zstd`.

- **plan** (`std7_170.plan`):
  - Эта таблица отслеживает данные о планировании продаж.
  - **Столбцы**: `date`, `region`, `matdirec`, `quantity`, `distr_chan`
  - **Партиционирование**: По `date` (на основе диапазона).
  - **Распределение**: Случайное.
  - **Сжатие**: `zstd`.

#### Таблицы справочников:
- **channel** (`std7_170.chanel`):
  - Эта таблица описывает каналы распределения.
  - **Столбцы**: `distr_chan`, `txtsh`
  - **Распределение**: Реплицированное.

- **price** (`std7_170.price`):
  - Эта таблица отслеживает информацию о ценах на продукцию.
  - **Столбцы**: `material`, `region`, `distr_chan`, `price`
  - **Распределение**: Реплицированное.

- **product** (`std7_170.product`):
  - Эта таблица предоставляет детали о продукции.
  - **Столбцы**: `material`, `asgrp`, `brand`, `matcateg`, `matdirec`, `txt`
  - **Распределение**: Реплицированное.

- **region** (`std7_170.region`):
  - Эта таблица описывает регионы.
  - **Столбцы**: `region`, `txt`
  - **Распределение**: Реплицированное.

### Ключевые особенности

1. **Партиционирование и распределение**:
   - Фактические таблицы `sales` и `plan` партиционированы по `date` для оптимизации временных запросов.
   - Распределения используются для балансировки нагрузки запросов.

2. **Сжатие данных**:
   - Применено сжатие `zstd` для экономии места и оптимизации производительности.

### Приобретенные навыки и компетенции

В ходе выполнения этого проекта я развил следующие навыки и компетенции:

- **Проектирование баз данных**: Получил опыт проектирования и реализации фактических и размерных таблиц, ориентированных на анализ данных о продажах.
- **Оптимизация запросов**: Улучшил навыки написания эффективных SQL-запросов и понимания того, как партиционирование и распределение могут повысить производительность.
- **Аналитическое мышление**: Углубил способность анализировать бизнес-требования и преобразовывать их в хорошо структурированное проектирование базы данных.

## Интеграция с внешними системами

### Описание выполненной работы

В этом разделе я описываю интеграцию с внешними системами через создание внешних таблиц в Greenplum. Цели и результаты следующие:

1. **Создание внешних таблиц с использованием протокола PXF**:
   - **Цель**: Обеспечить доступ к данным из существующих таблиц Postgres (`gp.plan` и `gp.sales`) в среде Greenplum.
   - **Результат**: Успешно созданы внешние таблицы, которые облегчают извлечение данных, что позволяет бесшовно интегрировать данные о продажах и планировании.
   - **Описание**: Протокол PXF (Pivotal Extension Framework) используется для подключения Greenplum к внешним источникам данных, что позволяет выполнять запросы к реляционным базам данных через JDBC.

2. **Создание внешних таблиц с использованием протокола gpfdist**:
   - **Цель**: Получение и управление данными, хранящимися в CSV-файлах (`price`, `chanel`, `product`, и `region`) с использованием протокола gpfdist.
   - **Результат**: Созданы внешние таблицы, позволяющие эффективно загружать данные из этих CSV-файлов в Greenplum, улучшая гибкость и доступность источников данных для анализа.
   - **Описание**: Протокол gpfdist позволяет Greenplum считывать данные из файлов, доступных по HTTP, что обеспечивает эффективную загрузку данных из распределённых файловых систем или облачного хранилища.

### Приобретенные навыки и компетенции

В ходе выполнения этой интеграционной работы я развил следующие навыки и компетенции:

- **Понимание интеграции данных**: Получил знания о том, как интегрировать разные источники данных с использованием различных протоколов, что повысило моё понимание рабочих процессов данных.
- **Профессионализм в Greenplum**: Улучшил свои навыки создания внешних таблиц и использования функций Greenplum для эффективного управления данными.
- **Знание протоколов доступа к данным**: Научился внедрять и использовать протоколы PXF и gpfdist, расширив свои знания о методах доступа к данным.
- **Аналитические навыки**: Улучшил свои способности анализировать структуры данных и точки интеграции, что привело к более эффективным стратегиям извлечения и анализа данных.
